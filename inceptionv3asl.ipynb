{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12459119,"sourceType":"datasetVersion","datasetId":7859476}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:42:08.628444Z","iopub.execute_input":"2025-07-15T11:42:08.628704Z","iopub.status.idle":"2025-07-15T11:42:28.242792Z","shell.execute_reply.started":"2025-07-15T11:42:08.628679Z","shell.execute_reply":"2025-07-15T11:42:28.242004Z"}},"outputs":[{"name":"stderr","text":"2025-07-15 11:42:11.689518: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752579732.045467      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752579732.142479      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train_dir = '/kaggle/input/newaslsinhala/datasetSinha/train'  \nval_dir = '/kaggle/input/newaslsinhala/datasetSinha/test'      \nimage_size = (224, 224)\nbatch_size = 32\nepochs = 10\nk_folds = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:42:28.243990Z","iopub.execute_input":"2025-07-15T11:42:28.244480Z","iopub.status.idle":"2025-07-15T11:42:28.248384Z","shell.execute_reply.started":"2025-07-15T11:42:28.244452Z","shell.execute_reply":"2025-07-15T11:42:28.247892Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\ndef load_image_paths(directory):\n    classes = sorted(os.listdir(directory))\n    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n    \n    image_paths = []\n    labels = []\n    \n    for cls_name in classes:\n        cls_dir = os.path.join(directory, cls_name)\n        for img_name in os.listdir(cls_dir):\n            img_path = os.path.join(cls_dir, img_name)\n            image_paths.append(img_path)\n            labels.append(class_to_idx[cls_name])\n    \n    return np.array(image_paths), np.array(labels), classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:42:28.249092Z","iopub.execute_input":"2025-07-15T11:42:28.249789Z","iopub.status.idle":"2025-07-15T11:42:28.280436Z","shell.execute_reply.started":"2025-07-15T11:42:28.249771Z","shell.execute_reply":"2025-07-15T11:42:28.279662Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_paths, train_labels, class_names = load_image_paths(train_dir)\nval_paths, val_labels, _ = load_image_paths(val_dir)\nnum_classes = len(class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:42:28.282172Z","iopub.execute_input":"2025-07-15T11:42:28.282374Z","iopub.status.idle":"2025-07-15T11:42:29.177362Z","shell.execute_reply.started":"2025-07-15T11:42:28.282359Z","shell.execute_reply":"2025-07-15T11:42:29.176779Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def create_model():\n    base_model = tf.keras.applications.InceptionV3(\n        input_shape=(224, 224, 3),\n        include_top=False,\n        weights='imagenet',\n        pooling='avg'\n    )\n    x = base_model.output\n    x = layers.Dense(1024, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n    model = models.Model(base_model.input, outputs)\n    \n    # Freeze base layers\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    model.compile(\n        optimizer=Adam(learning_rate=0.001),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:42:29.178024Z","iopub.execute_input":"2025-07-15T11:42:29.178231Z","iopub.status.idle":"2025-07-15T11:42:29.183244Z","shell.execute_reply.started":"2025-07-15T11:42:29.178215Z","shell.execute_reply":"2025-07-15T11:42:29.182543Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class CustomDataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, image_paths, labels, batch_size, img_size, shuffle=True):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return int(np.ceil(len(self.image_paths) / self.batch_size))\n    \n    def __getitem__(self, index):\n        batch_paths = self.image_paths[index*self.batch_size:(index+1)*self.batch_size]\n        batch_labels = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n        \n        batch_images = []\n        for path in batch_paths:\n            img = Image.open(path).convert('RGB')\n            img = img.resize(self.img_size)\n            img = np.array(img) / 255.0\n            batch_images.append(img)\n            \n        return np.array(batch_images), np.array(batch_labels)\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            shuffled_indices = np.random.permutation(len(self.image_paths))\n            self.image_paths = self.image_paths[shuffled_indices]\n            self.labels = self.labels[shuffled_indices]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:42:29.184069Z","iopub.execute_input":"2025-07-15T11:42:29.184278Z","iopub.status.idle":"2025-07-15T11:42:29.204676Z","shell.execute_reply.started":"2025-07-15T11:42:29.184257Z","shell.execute_reply":"2025-07-15T11:42:29.204129Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"all_paths = np.concatenate([train_paths, val_paths])\nall_labels = np.concatenate([train_labels, val_labels])\n\nkf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\nfold_history = []\nall_reports = []\nfor fold, (train_idx, val_idx) in enumerate(kf.split(all_paths)):\n    print(f\"\\n========== Fold {fold + 1}/{k_folds} ==========\")\n    \n    \n    train_gen = CustomDataGenerator(\n        all_paths[train_idx], all_labels[train_idx],\n        batch_size=batch_size, img_size=image_size, shuffle=True\n    )\n    \n    val_gen = CustomDataGenerator(\n        all_paths[val_idx], all_labels[val_idx],\n        batch_size=batch_size, img_size=image_size, shuffle=False\n    )\n    \n  \n    model = create_model()\n    history = model.fit(\n        train_gen,\n        epochs=epochs,\n        validation_data=val_gen,\n        verbose=1\n    )\n    fold_history.append(history.history)\n    \n   \n    y_true = val_gen.labels\n    y_pred = np.argmax(model.predict(val_gen), axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:42:29.205335Z","iopub.execute_input":"2025-07-15T11:42:29.205523Z"}},"outputs":[{"name":"stdout","text":"\n========== Fold 1/5 ==========\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752579750.909420      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1752579750.910118      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1752579766.850944      97 service.cc:148] XLA service 0x783220002450 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1752579766.852363      97 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1752579766.852387      97 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1752579768.829044      97 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/459\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 100ms/step - accuracy: 0.0547 - loss: 4.8110  ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752579776.453095      97 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 647ms/step - accuracy: 0.6536 - loss: 1.4118 - val_accuracy: 0.9408 - val_loss: 0.1943\nEpoch 2/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 307ms/step - accuracy: 0.9349 - loss: 0.2068 - val_accuracy: 0.9555 - val_loss: 0.1403\nEpoch 3/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 306ms/step - accuracy: 0.9518 - loss: 0.1471 - val_accuracy: 0.9389 - val_loss: 0.1818\nEpoch 4/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 304ms/step - accuracy: 0.9622 - loss: 0.1115 - val_accuracy: 0.9659 - val_loss: 0.1056\nEpoch 5/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 299ms/step - accuracy: 0.9646 - loss: 0.1060 - val_accuracy: 0.9629 - val_loss: 0.1064\nEpoch 6/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 303ms/step - accuracy: 0.9699 - loss: 0.0894 - val_accuracy: 0.9490 - val_loss: 0.1521\nEpoch 7/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 297ms/step - accuracy: 0.9743 - loss: 0.0731 - val_accuracy: 0.9561 - val_loss: 0.1338\nEpoch 8/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 291ms/step - accuracy: 0.9764 - loss: 0.0734 - val_accuracy: 0.9607 - val_loss: 0.1182\nEpoch 9/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 304ms/step - accuracy: 0.9748 - loss: 0.0739 - val_accuracy: 0.9545 - val_loss: 0.1432\nEpoch 10/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 306ms/step - accuracy: 0.9719 - loss: 0.0833 - val_accuracy: 0.9525 - val_loss: 0.1545\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 285ms/step\n\n========== Fold 2/5 ==========\nEpoch 1/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 323ms/step - accuracy: 0.6677 - loss: 1.2564 - val_accuracy: 0.9351 - val_loss: 0.2192\nEpoch 2/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 305ms/step - accuracy: 0.9338 - loss: 0.2166 - val_accuracy: 0.9504 - val_loss: 0.1500\nEpoch 3/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 297ms/step - accuracy: 0.9533 - loss: 0.1402 - val_accuracy: 0.9596 - val_loss: 0.1300\nEpoch 4/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 303ms/step - accuracy: 0.9584 - loss: 0.1266 - val_accuracy: 0.9651 - val_loss: 0.1024\nEpoch 5/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 297ms/step - accuracy: 0.9641 - loss: 0.1032 - val_accuracy: 0.9596 - val_loss: 0.1404\nEpoch 6/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 292ms/step - accuracy: 0.9672 - loss: 0.0924 - val_accuracy: 0.9569 - val_loss: 0.1468\nEpoch 7/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 303ms/step - accuracy: 0.9666 - loss: 0.1001 - val_accuracy: 0.9621 - val_loss: 0.1159\nEpoch 8/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 298ms/step - accuracy: 0.9725 - loss: 0.0828 - val_accuracy: 0.9610 - val_loss: 0.1319\nEpoch 9/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 302ms/step - accuracy: 0.9712 - loss: 0.0906 - val_accuracy: 0.9733 - val_loss: 0.0923\nEpoch 10/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 301ms/step - accuracy: 0.9775 - loss: 0.0673 - val_accuracy: 0.9719 - val_loss: 0.0971\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 295ms/step\n\n========== Fold 3/5 ==========\nEpoch 1/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 339ms/step - accuracy: 0.6655 - loss: 1.3282 - val_accuracy: 0.9335 - val_loss: 0.2244\nEpoch 2/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 302ms/step - accuracy: 0.9302 - loss: 0.2130 - val_accuracy: 0.9498 - val_loss: 0.1618\nEpoch 3/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 304ms/step - accuracy: 0.9554 - loss: 0.1414 - val_accuracy: 0.9566 - val_loss: 0.1292\nEpoch 4/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 309ms/step - accuracy: 0.9610 - loss: 0.1188 - val_accuracy: 0.9569 - val_loss: 0.1360\nEpoch 5/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 310ms/step - accuracy: 0.9675 - loss: 0.0959 - val_accuracy: 0.9599 - val_loss: 0.1177\nEpoch 6/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 321ms/step - accuracy: 0.9727 - loss: 0.0822 - val_accuracy: 0.9485 - val_loss: 0.1495\nEpoch 7/10\n\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 304ms/step - accuracy: 0.9691 - loss: 0.1045 - val_accuracy: 0.9686 - val_loss: 0.0967\nEpoch 8/10\n\u001b[1m210/459\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 250ms/step - accuracy: 0.9765 - loss: 0.0740","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"report = classification_report(y_true, y_pred, target_names=class_names)\nprint(\"\\nClassification Report:\")\nprint(report)\nall_reports.append(report)\n    \n    # Confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names)\nplt.title(f'Confusion Matrix - Fold {fold + 1}')\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_classes = np.random.choice(num_classes, size=min(3, num_classes), replace=False)\ny_prob = model.predict(val_gen)\ny_true_bin = label_binarize(y_true, classes=np.arange(num_classes))\n    \nplt.figure(figsize=(8, 6))\nfor i in sample_classes:\n    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n    \nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(f'ROC Curves (Sample) - Fold {fold + 1}')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_classes = np.random.choice(num_classes, size=min(5, num_classes), replace=False)\ny_prob = model.predict(val_gen)\ny_true_bin = label_binarize(y_true, classes=np.arange(num_classes))\n    \nplt.figure(figsize=(8, 6))\nfor i in sample_classes:\n    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n    \nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(f'ROC Curves (Sample) - Fold {fold + 1}')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nTraining final model on all data...\")\nfull_train_gen = CustomDataGenerator(all_paths, all_labels, batch_size, image_size)\nfinal_model = create_model()\nfinal_model.fit(full_train_gen, epochs=epochs)\n# Save final model\nfinal_model.save('/kaggle/working/final_model_trained_on_all_InceptionV3.h5')\nprint(\"Final model saved as 'final_model_trained_on_all_data.h5'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_training_history(history):\n    plt.figure(figsize=(12, 4))\n    \n    # Plot training & validation accuracy values\n    plt.subplot(1, 2, 1)\n    plt.plot(history['accuracy'])\n    plt.plot(history['val_accuracy'])\n    plt.title('Model Accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    \n    # Plot training & validation loss values\n    plt.subplot(1, 2, 2)\n    plt.plot(history['loss'])\n    plt.plot(history['val_loss'])\n    plt.title('Model Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    \n    plt.tight_layout()\n    plt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n=== Classification Reports for All Folds ===\")\nfor i, report in enumerate(all_reports, 1):\n    print(f\"\\nFold {i}:\\n{report}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}